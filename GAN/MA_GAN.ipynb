{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnabla as nn\n",
    "\n",
    "import nnabla.functions as F\n",
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.solvers as S\n",
    "from nnabla.monitor import tile_images\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "mb_size = 64\n",
    "Z_dim = 128\n",
    "X_dim = mnist.train.images.shape[1]\n",
    "y_dim = mnist.train.labels.shape[1]\n",
    "lr = 1e-3\n",
    "\n",
    "d_step = 3\n",
    "lr = 1e-3\n",
    "m = 5\n",
    "n_iter = 1000\n",
    "n_epoch = 1000\n",
    "N = n_iter * mb_size  # N data per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def G(z, hidden=[128, 128]):\n",
    "    hs = []\n",
    "    with nn.parameter_scope(\"G\"):  # Parameter scope can be nested\n",
    "        h = z\n",
    "        for hid, hsize in enumerate(hidden):\n",
    "            with nn.parameter_scope(\"affine{}\".format(hid + 1)):\n",
    "                h = F.relu(PF.affine(h, hsize))\n",
    "                hs.append(h)\n",
    "        with nn.parameter_scope(\"last_layer\"):\n",
    "            X = F.sigmoid(PF.affine(h, X_dim))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def D(X, hidden=[128]):\n",
    "    hs = []\n",
    "    with nn.parameter_scope(\"D\"):  # Parameter scope can be nested\n",
    "        h = X\n",
    "        for hid, hsize in enumerate(hidden):\n",
    "            with nn.parameter_scope(\"affine{}\".format(hid + 1)):\n",
    "                h = F.relu(PF.affine(h, hsize))\n",
    "                hs.append(h)\n",
    "        with nn.parameter_scope(\"reconstruction\"):\n",
    "            X_recon = PF.affine(h, X_dim)      \n",
    "    return F.sum((X - X_recon)**2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_solver = S.Adamax(lr)\n",
    "with nn.parameter_scope(\"G\"):\n",
    "    G_solver.set_parameters(nn.get_parameters())\n",
    "    \n",
    "D_solver = S.Adamax(lr)\n",
    "with nn.parameter_scope(\"D\"):\n",
    "    D_solver.set_parameters(nn.get_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_grad():\n",
    "    G_solver.zero_grad()\n",
    "    D_solver.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show16(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain discriminator\n",
    "for it in range(2*n_iter):\n",
    "    X, _ = mnist.train.next_batch(mb_size)\n",
    "    X = nn.Variable.from_numpy_array(X)\n",
    "\n",
    "    loss = F.mean(D(X))  # Minimize real samples energy\n",
    "\n",
    "    loss.forward()\n",
    "    loss.backward()\n",
    "    D_solver.update()\n",
    "    reset_grad()\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Step: {}, Pretrained D loss: {:.4}'.format(it, loss.d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial margin, expected energy of real data\n",
    "m = F.mean(D(nn.Variable.from_numpy_array(mnist.train.images))).d\n",
    "s_z_before = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(n_epoch):\n",
    "    s_x, s_z = np.zeros(1), np.zeros(1)\n",
    "    for it in range(n_iter):\n",
    "        # Discriminator\n",
    "        X, _ = mnist.train.next_batch(mb_size)\n",
    "        X = nn.Variable.from_numpy_array(X)\n",
    "        z = nn.Variable.from_numpy_array(np.random.randn(mb_size, Z_dim))\n",
    "\n",
    "        G_sample = G(z)\n",
    "        D_real = D(X)\n",
    "        D_fake = D(G_sample)\n",
    "\n",
    "        D_loss = F.mean(D_real) + F.relu(m - F.mean(D_fake))\n",
    "\n",
    "        D_loss.forward()\n",
    "        D_loss.backward() # Applying weight decay as an regulariation\n",
    "        D_solver.update()\n",
    "\n",
    "        # Update real samples statistics\n",
    "        s_x += np.sum(D_real.d)\n",
    "\n",
    "        reset_grad()\n",
    "\n",
    "        # Generator Update\n",
    "        z_G = nn.Variable.from_numpy_array(np.random.randn(mb_size, Z_dim))\n",
    "        G_sample = G(z)\n",
    "        D_fake = D(G_sample)\n",
    "        \n",
    "        G_loss = F.mean(D_fake)\n",
    "\n",
    "        G_loss.forward()\n",
    "        G_loss.backward()\n",
    "        G_solver.update()\n",
    "        \n",
    "        # Update fake samples statistics\n",
    "        s_z += np.sum(D_fake.d)\n",
    "\n",
    "        reset_grad()\n",
    "    \n",
    "    # Update margin\n",
    "    if (((s_x[0] / N) < m) and (s_x[0] < s_z[0]) and (s_z_before[0] < s_z[0])):\n",
    "        m = s_x[0] / N\n",
    "\n",
    "    s_z_before = s_z\n",
    "\n",
    "    # Convergence measure\n",
    "    Ex = s_x[0] / N\n",
    "    Ez = s_z[0] / N\n",
    "    L = Ex + np.abs(Ex - Ez)\n",
    "    # Generate and Show Samples \n",
    "    print('Step: {}, m = {}, L = {}'.format(it, m, L))\n",
    "        \n",
    "    samples = G(z_G).d[:16]\n",
    "    show16(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}